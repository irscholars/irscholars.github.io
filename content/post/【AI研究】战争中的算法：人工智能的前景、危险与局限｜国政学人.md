---
title: 【AI研究】战争中的算法：人工智能的前景、危险与局限｜国政学人
date: 2021-02-17 19:55:00
author: 国政学人
tags: 
---


收录于合集

![](/images/1205/2.jpeg)

  

**作品简介**

 **【作者】** 本杰明·詹森(Benjamin M.
Jensen)，美国海军陆战队大学高级战斗学院战略研究教授；克里斯托弗·怀特(Christopher
Whyte)，弗吉尼亚联邦大学道格拉斯·怀尔德政府与公共事务学院助理教授；斯科特·科莫(Scott A. Cuomo)，美国海军陆战队上尉。

 **【编译】** 常佳艺（国政学人编译员，北京大学国际关系学院本科生）

 **【校对】** 杨稚珉

 **【审核】** 朱晓洁

 **【排版】** 高思慧

 **【美编** 】李九阳

 **【来源】** Benjamin M Jensen, Christopher Whyte, Scott Cuomo, Algorithms at
War: The Promise, Peril, and Limits of Artificial Intelligence, _International
Studies Review_ , Volume 22, Issue 3, September 2020, Pages 526–550,
https://doi.org/10.1093/isr/viz025.

 **【归档】** 《国际关系前沿》2021年第2期，总第29期。

  

 **期刊简介**

  

<img src='/images/1205/3.png' width='100%' />

  

《国际研究评论》（International Studies Review）是由牛津大学出版社代表国际研究协会（International Studies
Association）出版的同行评审学术期刊，以季刊形式发行。该刊旨在帮助：(a)学者进行将影响未来国际研究领域的对话和辩论；(b)研究生和本科生了解国际研究的主要问题，并发现有前途的研究机会；(c)教育者跟上新思想和新研究。该刊2019年影响因子2.232。

  

<img src='/images/1205/4.jpeg' width='25' height='25' />

 **战争中的算法:**

 **人工智能的前景、危险与局限**

 **Algorithms at War:**

 **The Promise, Peril, and Limits of Artificial Intelligence**

  

![](/images/1205/5.png)

Benjamin M. Jensen

![](/images/1205/6.png)

Christopher Whyte

  

<img src='/images/1205/7.png' width='100%' />

Scott A. Cuomo

  

 **内容提要**

  

人工智能（AI）技术的快速发展将如何影响军事力量的建设和使用？尽管人工智能系统在国防现代化计划中的重要性日益显现，但从国际关系和安全研究角度出发的经验或理论研究却有所欠缺。本文通过描述人工智能的发展并评估人工智能影响军事组织的可能方式以弥补这一缺陷。作者聚焦于人工智能对于军事力量的影响，因为军事力量的新方法和新模式将改变世界各地安全关系的构成，并影响各国在21世纪进行谈判、释放信号和施加影响的能力。作者认为，虽然新技术有望在某些方面改变军事力量的特征，但它也使安全机构决策和官僚互动的认知领域变得复杂。综合性人工智能系统使全新的战争模式得以实现，但其速度之快也会在若干层次中以潜在方式使人类机构脱离战争进程。为防止这些“机器里的幽灵”（ghosts
in the machine）产生负外部性，加强决策者培训力度、促进问责制的健全以及限制不负责任的人工智能应用显得极为必要。

  

 **文章导读**

  

 **01**

 **人工智能与军事力量**

最近发布的《2018年美国国防战略》（NDS）指出，人工智能等领域快速的技术进步正在改变战争的性质。随着人工智能的应用领域不断扩展，其作用也变得至关重要。国家能够发动“算法战争（algorithmic
warfare）”，将情报、监视和侦察任务自动化，以在打响第一枪之前赢得信息战的胜利。而在此过程中，利用AI应用收集和理解数据能力最强的国家，将实现长期竞争优势。热衷于人工智能技术的学者强调，人工智能是一种颠覆性的创新，这些能够学习、感知和移动的机器有可能成为一种变革性的国家安全技术，与核武器、飞机、计算机和生物技术齐名。在国家安全决策的制度和认知层面，人工智能将打破速度、成本和质量之间的权衡，提高效率和产出。此外，这种颠覆性影响也会迅速扩散。国防实验室和主要国防制造商在人工智能方面的投入远不及商业汽车或信息和通信部门，且对最有能力的技术人员吸引力较小。在战略层面，人工智能的引入可能会让崛起的大国作为新的市场进入者，取代美国等既有的军事强国。这些说法都认为，整合能学习、能感知、能移动的人工智能系统将提高军事力量。

  

尽管人工智能前景广阔，但核心问题是人工智能将会如何与人类组织和决策机构碰撞进而影响军事力量。军事力量作为衡量国家如何在战场上使用有组织的暴力或威慑敌人的尺度，涉及“硬件”和“软件”两方面的考虑。硬件是“用于战斗的技术组合”，而软件是“用于实际运用硬件的组织流程”。以航空母舰为例，仅仅发明这种新技术是不够的，为了取得优势地位，需要建设从理论到训练到招募人员的一系列组织流程，以将航母这个硬件整合到更广泛的海战体系中。同理也适用于将人工智能整合至军事组织系统中
--
从招募人员到接受训练和教育，再到学习概念和理论，这些与技术本身一样重要。事实上，技术革新的前景往往与相对稳定的政治体制与机构相冲突。因此，当人们将新技术融入政治与军事事务时，新技术与社会和制度因素交织在一起，减缓了新技术从实验室走向战线的速度，因而进化性的渐变比革命性的突变更为常见。就历史而言，类似于战争爆发的重大政治事件应由政治来解释，而非技术变革导致的军力平衡变化解释。

  

尽管人工智能有前景也有危险，但其对军事力量以及战争特性带来的影响却受到两个重要因素的限制，即整合和计算（integration and
calculation）。

  

从整合的角度而言，虽然人工智能自主系统有可能改变军事力量，但各国军队在整合过程中将不可避免地面临法律、组织、文化和技术挑战。首先，军方和军队在采用人工智能时将受到自主系统运行的法律标准和大数据驱动下情报功能的发展标准的限制。第二，不断发展的战略动态使这种法律限制的完整性受到质疑，一些对手将在定义不清的空间之内寻求建立新的行为规范。第三，人工智能的应用将不可避免地受到国家军队内部体制和文化偏好的影响。第四，各军事分队在使用人工智能时临时创新（ad
hoc innovations）所带来的积极和消极结果。这些因素将对人工智能如何被纳入现有的军事机制以及其可行性本身产生重要影响。

  

即使各国在部署人工智能系统时克服了“整合”这一挑战，人类的决策仍然会给机器决策蒙上阴影。理论上，人工智能应该降低军事行动的成本，增加预期收益。在战术层面之外，这些转移的成本有可能改变讨价还价理论核心的“风险-
收益权衡”（risk-return trade-
off）。因此，第一个全面融入人工智能的国家有可能获得竞争优势地位。然而，虽然人工智能的战术和作战效益是明确的，但战略效果是不确定的。首先，对军事实力和战略意图的预估容易出现过度简化的误差。安德鲁·马歇尔在1966年为兰德公司进行的一项研究中指出，国家间军事力量的比较并非兵力比计算（force-
ratio
calculation）。大多数分析倾向于将军事力量从其制度和政治背景中剥离出来，而避免处理与军力相关的地理、后勤和训练效果等问题。此外，大多数分析都倾向于将政府、军事组织等等同于理性的决策个体，而非事实上的复杂官僚机构。虽然人工智能可以比人类更快地处理更多样化的数据流，但算法仍然面临假设过于简化的问题。

  

其二，人工智能会产生形式独特的算法偏差。这种偏差在复杂系统中层层叠加，往往会产生意想不到的结果。以识别文本和图像的传感错误（sensing
errors）为例，如果军事情报专业人员进入一个有缺陷的图像识别系统，通过数百张照片的评估将敌方战斗人员定位在一个充满数十万非战斗人员的城市地区，一旦产生错误，既会对眼前的战术任务造成不利影响，也极有可能带来国内和国际上的重大政治损失。

  

其三，当科技行业开始创造人工智能时，它有可能将种族主义和其他偏见插入到代码中而难以像人类一样自行纠偏。

  

其四，与算法相比，决策者更有可能根据当下生动的例子和主观可信度进行计算，历史类比也会在外交决策和军事战略形成过程中发挥作用。例如，在战略层面，美国总统卡特等领导人在1979年与苏联领导人的个人接触比情报界对军事能力的估计更具影响力。深度学习算法以一种深思熟虑的、经过计算的方式对一系列战略事件进行观察，并不意味着领导者就能克服自己的主观信念和经验。

  

还有一个更深层次的问题，那就是在战争这样的复杂系统中，能够达到何种程度的确定性。普鲁士军事理论家卡尔·冯·克劳塞维茨认为“战争是偶然的领域……指挥官不断地发现事情并不像他所期望的那样”。作为一个非线性系统，每场战斗和战役都受偶然因素所支配。在这种不确定性之外，军事能力，即硬件加上软件，在实战中的每一次变化，都会产生相应的反应。军事创新与战场失败（battlefield
setbacks）共同导致战术适应（tactical adaption）。在军事理论中，这种反馈循环（feedback
loop）使计划和执行变得复杂。战争不完全是科学，人工智能改变军事实力的程度将取决于战术适应的范围与速度，这两者都是人类在不确定性下的创造力和判断力的体现。

  

最后，新技术可以改变军事力量，但战争在现在和将来都是政治的延续。在战略层面，关于可信度和声誉的问题是实际军事力量的关键部分。当弱国认为自己的生存受到威胁时，即使是最可信的军事威胁，也会倾向于抵抗。换句话说，即使美国率先集体部署人工智能系统，由此带来的军事实力提升也不能保证战略成果。此外，声誉也起着一定的作用。人工智能会增加一个国家的力量，但声誉是一种基于地位、过去的行为和政治背景的政治效应，决策者会根据对手过去的行动，或者更有可能是当前的环境来权衡他们的选择，而不是孤立地看军事力量。

  

 **02**

 **前景：算法增强还是机器中的幽灵？**

人工智能如何影响国际体系中的军事力量平衡，可能是21世纪的一个决定性问题。然而，仅凭技术不会改变国家备战、威胁对手与战斗的方式。实际上，技术和军事力量的互动是一个反复地吸收、借鉴和塑造着人类认知的复杂的过程。关于学习、感知和移动机器理论的概括将会忽略新的硬件与人类的制度和判断互动中“非线性的、偶然的与机缘巧合的”方式。

  

人工智能的前景很可能会被人类机制和判断的复杂性所抵消。现代国防官僚机构仍然会在地盘和资源上展开激烈的争斗，这些争斗会减缓、甚至直接破坏人工智能技术的应用。因此，以规划未来战争、理解对手意图并最终使用武力追求政治目标为目的的深度学习和人类判断在军事范围内的快速整合几乎是不可能的。

  

尽管如此，不可否认的是，我们正站在或接近一个拐点，信息和机器人技术、计算基础设施的进展预示着军事力量的形态将在近期发生一系列前所未有的变化。作者认为，从上述关于计算和整合局限性的讨论中得到的核心启示是简单且合理的：研究者和实践者都必须考虑当人工智能完全整合到各个军事职能部门之后，它在国际安全事务中可能会在多大程度上作为“机器中的幽灵”出现。由于操作者和决策者往往无法或不愿考虑人工智能系统得出结论的方式，复杂的机器学习基础会使人类的深思熟虑脱离经验。一个被灌输了关于即将发生攻击的概率数据的指挥官或文职领导人，可能不知道如何质疑结论的有效性。同样，因为担心在面对看似合理、可操作的情报时出现道德失范（ethical
misconduct），这样的领导者也可能不屑于质疑结论。

  

这种对人工智能的局限性可能扭曲人类对审议和执行军事进程的控制的担忧，从根本上指出了与新技术融合相关的一系列问责和激励挑战。人工智能系统的应用必须由人类的系统加以塑造，以减轻被委托的人工智能的负面效应。这样做不仅可以使军队内部免受人工智能幽灵的负外部性影响，而且还可以将向对手发出的信号明确化。

  

 **03**

 **  
**

 **结论**

建立一个研究人工智能将如何塑造国际安全关系的分析框架的第一步，是识别影响不同国家以及非国家行为体如何使用算法进行战争的可能干预因素。从实证研究到历史案例，安全研究的学者们给实践者们提供了理性的思考，这些研究有助于描述并将变革性技术与人类制度和判断发生冲突的机制可视化。在技术决定论者眼中，人工智能群(AI
swarms)将发动无风险的战争，而激进分子则警告称将出现“杀戮机器人”（slaughter bots），这可能助长扭曲国防支出和安全政策的通胀威胁。

  

随着各国通过推动更加精细的手段，将战争中的商议和执行过程自动化，是否有可能看到人工智能领域的军备竞赛？作者认为，目前新出现的机器人技术领域的变革还不足以保证改变国家在重大冲突中取胜的能力。这种情况或许在未来会改变。然而，就目前而言，在战争中使用人工智能所带来的制度风险比近期应用人工智能技术本身所带来的风险更严重。

  

总结上文各节的分析，作者建议从下列五个独立方向进行深入研究。第一，关于中短期内在人工智能技术支持下的国际冲突形态的学术研究，最好能考虑到对西方军队应用新信息技术的法律约束因素。第二，与此相关的是，学者们或许可以通过推断关键对手可能在哪些方面推波助澜，试图在尚无争议的空间中形成有利的自主互动规范（norms
of autonomous interaction），从而有效地判定国际事务中危机管理的威慑性和强制性框架的可行性（viability of
deterrent and coercive
frameworks）。第三，在创新和克服社会体制障碍时，有必要努力弥合实践和学术理论之间的差距，注重历史的教训。第四，应极力避免忽视人工智能使用和发展的潜在的自下而上的来源（bottom-
up
sources）。在使用具有学习、感知和移动能力的机器方面，许多颠覆性的进步将来自私营部门与部署在冲突前线的军事次级组织的即兴经验（improvisational
experience）。最后，关于国际安全的学术研究必须关注人工智能应用过程中不断出现的人类认知-心理学上的决定因素。

  

幸运的是，在上述方向中，即使是专注于狭义技术的人工智能革命也只需要与国际政治和安全方面的大量文献中的传统既定概念进行新的衔接。现在摆在国际关系学者面前的任务是运用这个巨大的工具箱，努力解决将人工学习与人类认知相关联的关键问题。

  

 **译者评述**

  

1950年，英国科学家图灵首次提出“图灵测试”与人工智能的概念。此后几十年来，人工智能在经济活动与社会生活中逐渐得到广泛应用，在部分特定领域接近乃至超越人类，也因此引起了广泛争议与讨论。作为一种前景广阔且具有相当不确定性乃至危险性的新技术，人工智能必将如同核武器一样，重新塑造当今国际关系与国际格局。在这一前提之下，作者聚焦于人工智能对于军事力量以及战争行为的影响，指出尽管人工智能技术有可能重塑战争形态并改变各国军力平衡，但国家仍必须从现代国防官僚机构之中发动算法战争，由此产生的计划和战斗仍将涉及人类的判断。政治官僚与社会文化规范等限制将使不同国家形成不同的人工智能应用方式，也将影响人工智能可能改变军事力量的程度。

  

目前，将人工智能与国际关系相结合的研究尚显欠缺，对于科学技术对于国际关系的影响力往往会有过高的预期。此外，此类预测往往高估了科技给人类带来的困难，却低估了人类解决困难的意愿与能力。作者在本文中并未提及到多边主义以及国际机制可能扮演的角色，而人类的跨国合作与交流在很大程度上可以通过构建严密的伦理道德与法律规范网络解决技术演进带来的挑战。

  

文章观点不代表本平台观点，本平台评译分享的文章均出于专业学习之用, 不以任何盈利为目的，内容主要呈现对原文的介绍，原文内容请通过各高校购买的数据库自行下载。

![](/images/1205/8.gif)

**好好学习，天天“在看”**<img src='/images/1205/9.gif' width='17' height='17' />

<img src='/images/1205/10.png' width='100%' />

![]()

国政学人

支持学术公益与知识传播

![赞赏二维码]() **微信扫一扫赞赏作者** __赞赏

已喜欢，[对作者说句悄悄话](javascript:;)

取消 __

#### 发送给作者

发送

最多40字，当前共字

[](javascript:;) 人赞赏

上一页 [1](javascript:;)/3 下一页

长按二维码向我转账

支持学术公益与知识传播

![赞赏二维码]()

受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。

